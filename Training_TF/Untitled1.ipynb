{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "import six\n",
    "from six.moves import range\n",
    "import csv\n",
    "import math as ma\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score,roc_curve,auc,precision_recall_curve\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop,Adam, Adadelta, Nadam, Adamax, SGD, Adagrad\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import  Dropout, Activation, Flatten\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from keras.constraints import maxnorm\n",
    "#from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, LSTM, Bidirectional\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " h5filename = \"histonemodTF_resample_ncl_GM12878.h5\"\n",
    " h5file = h5.File(h5filename,'r')\n",
    " input_features = h5file['input/H3K27ac_RPKM']\n",
    " output_H3K4me3 = h5file['output/H3K27ac']\n",
    " \n",
    " input_features = np.array(input_features)\n",
    " output_H3K4me3 = np.array(output_H3K4me3)\n",
    " output_H3K4me3_reshape = output_H3K4me3.reshape(len(output_H3K4me3),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7826, 52)\n",
      "(18185, 52)\n"
     ]
    }
   ],
   "source": [
    " #combine the label with input dna  \n",
    "input_features_label = np.concatenate((input_features,output_H3K4me3_reshape), axis=1)\n",
    "H3K4me3_df = pd.DataFrame(output_H3K4me3)\n",
    "pos_label= H3K4me3_df.loc[H3K4me3_df.iloc[:,0]==1]\n",
    "pos_label_ix = np.array(pos_label.index)\n",
    "neg_label = H3K4me3_df.loc[H3K4me3_df.iloc[:,0]==0]\n",
    "neg_label_ix = np.array(neg_label.index)\n",
    "pos_sam_H3K4me3 = input_features_label[pos_label_ix,:]\n",
    "neg_sam_H3K4me3 = input_features_label[neg_label_ix,:]\n",
    "np.random.shuffle(pos_sam_H3K4me3)\n",
    "np.random.shuffle(neg_sam_H3K4me3)\n",
    "print(pos_sam_H3K4me3.shape)\n",
    "print(neg_sam_H3K4me3.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18209, 51)\n",
      "(18209,)\n",
      "[0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#trainset\n",
    "#if K562 set y to 43, for H1 set y to 30 and for GM12878 set y to 51 \n",
    "train_neg_sample = int(ma.ceil(neg_sam_H3K4me3.shape[0] *0.7))\n",
    "train_pos_sample = int(ma.ceil(pos_sam_H3K4me3.shape[0] *0.7))\n",
    "train_neg_H3K4me3 = neg_sam_H3K4me3[0:train_neg_sample,:]\n",
    "train_pos_H3K4me3 = pos_sam_H3K4me3 [0:train_pos_sample,:]\n",
    "train_neg_pos_H3K4me3 = np.concatenate((train_neg_H3K4me3, train_pos_H3K4me3),axis = 0)\n",
    "np.random.shuffle(train_neg_pos_H3K4me3)\n",
    "X_train_H3K4me3 = train_neg_pos_H3K4me3[:,0:51]\n",
    "Y_train_H3K4me3 = train_neg_pos_H3K4me3[:,51]\n",
    "Y_train_H3K4me3 = np.array(Y_train_H3K4me3, dtype='int8')\n",
    "frq = np.bincount(Y_train_H3K4me3)\n",
    "#print(frq)\n",
    "print(X_train_H3K4me3.shape)\n",
    "print(Y_train_H3K4me3.shape)\n",
    "print(Y_train_H3K4me3[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1819  783]\n",
      "(2602, 51)\n",
      "(2602,)\n",
      "(2602, 51)\n"
     ]
    }
   ],
   "source": [
    "#validation set\n",
    "val_neg_sample = train_neg_sample + int(ma.ceil(neg_sam_H3K4me3.shape[0] *0.1))\n",
    "val_pos_sample = train_pos_sample + int(ma.ceil(pos_sam_H3K4me3.shape[0] *0.1))\n",
    "val_neg_H3K4me3 = neg_sam_H3K4me3[train_neg_sample:val_neg_sample,:]\n",
    "val_pos_H3K4me3 = pos_sam_H3K4me3[train_pos_sample:val_pos_sample,:]\n",
    "val_neg_pos_H3K4me3 = np.concatenate((val_neg_H3K4me3, val_pos_H3K4me3),axis = 0)\n",
    "np.random.shuffle(val_neg_pos_H3K4me3)\n",
    "X_val_H3K4me3 = val_neg_pos_H3K4me3[:,0:51]\n",
    "Y_val_H3K4me3 = val_neg_pos_H3K4me3[:,51]\n",
    "Y_val_H3K4me3 = np.array(Y_val_H3K4me3, dtype='int8')\n",
    "frq = np.bincount(Y_val_H3K4me3)\n",
    "print(frq)\n",
    "print(X_val_H3K4me3.shape)\n",
    "print(Y_val_H3K4me3.shape)   \n",
    "print(X_val_H3K4me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3636 1564]\n",
      "(5200, 51)\n",
      "(5200,)\n"
     ]
    }
   ],
   "source": [
    "#test set\n",
    "test_neg_H3K4me3 = neg_sam_H3K4me3[val_neg_sample:,:]\n",
    "test_pos_H3K4me3 = pos_sam_H3K4me3 [val_pos_sample:,:]\n",
    "test_neg_pos_H3K4me3 = np.concatenate((test_neg_H3K4me3, test_pos_H3K4me3),axis = 0)\n",
    "np.random.shuffle(test_neg_pos_H3K4me3)\n",
    "X_test_H3K4me3 = test_neg_pos_H3K4me3[:,0:51]\n",
    "Y_test_H3K4me3 = test_neg_pos_H3K4me3[:,51]\n",
    "Y_test_H3K4me3 = np.array(Y_test_H3K4me3, dtype='int8')\n",
    "frq = np.bincount(Y_test_H3K4me3)\n",
    "print(frq)\n",
    "print(X_test_H3K4me3.shape)\n",
    "print(Y_test_H3K4me3.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 256)               13312     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 180)               46260     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 60)                10860     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 70,493\n",
      "Trainable params: 70,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, input_dim= 51, activation=\"relu\",kernel_initializer='glorot_uniform')) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=180,  activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units= 60, activation=\"relu\",kernel_initializer='glorot_uniform')) \n",
    "model.add(Dense(units=1,  activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running at most 60 epochs\n",
      "Train on 18209 samples, validate on 2602 samples\n",
      "Epoch 1/90\n",
      "17984/18209 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.8974\n",
      "Epoch 00001: val_loss improved from inf to 0.19161, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 6s 308us/step - loss: 0.3045 - acc: 0.8978 - val_loss: 0.1916 - val_acc: 0.9427\n",
      "Epoch 2/90\n",
      "18208/18209 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9481\n",
      "Epoch 00002: val_loss improved from 0.19161 to 0.17258, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 190us/step - loss: 0.1811 - acc: 0.9481 - val_loss: 0.1726 - val_acc: 0.9485\n",
      "Epoch 3/90\n",
      "18144/18209 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9525\n",
      "Epoch 00003: val_loss improved from 0.17258 to 0.16704, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 4s 207us/step - loss: 0.1596 - acc: 0.9526 - val_loss: 0.1670 - val_acc: 0.9485\n",
      "Epoch 4/90\n",
      "18192/18209 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9559\n",
      "Epoch 00004: val_loss improved from 0.16704 to 0.14958, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 173us/step - loss: 0.1508 - acc: 0.9560 - val_loss: 0.1496 - val_acc: 0.9485\n",
      "Epoch 5/90\n",
      "18096/18209 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9579\n",
      "Epoch 00005: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.1361 - acc: 0.9578 - val_loss: 0.1559 - val_acc: 0.9531\n",
      "Epoch 6/90\n",
      "18080/18209 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9598\n",
      "Epoch 00006: val_loss improved from 0.14958 to 0.13154, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 172us/step - loss: 0.1344 - acc: 0.9599 - val_loss: 0.1315 - val_acc: 0.9531\n",
      "Epoch 7/90\n",
      "17984/18209 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9613\n",
      "Epoch 00007: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 174us/step - loss: 0.1282 - acc: 0.9615 - val_loss: 0.1429 - val_acc: 0.9566\n",
      "Epoch 8/90\n",
      "18112/18209 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9614\n",
      "Epoch 00008: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 173us/step - loss: 0.1280 - acc: 0.9614 - val_loss: 0.1473 - val_acc: 0.9570\n",
      "Epoch 9/90\n",
      "18016/18209 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9638\n",
      "Epoch 00009: val_loss improved from 0.13154 to 0.12683, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 172us/step - loss: 0.1158 - acc: 0.9634 - val_loss: 0.1268 - val_acc: 0.9577\n",
      "Epoch 10/90\n",
      "17984/18209 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9649\n",
      "Epoch 00010: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.1177 - acc: 0.9647 - val_loss: 0.1305 - val_acc: 0.9539\n",
      "Epoch 11/90\n",
      "17904/18209 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9654\n",
      "Epoch 00011: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.1103 - acc: 0.9656 - val_loss: 0.1289 - val_acc: 0.9566\n",
      "Epoch 12/90\n",
      "17936/18209 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9655\n",
      "Epoch 00012: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.1081 - acc: 0.9658 - val_loss: 0.1278 - val_acc: 0.9573\n",
      "Epoch 13/90\n",
      "18176/18209 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9661\n",
      "Epoch 00013: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.1072 - acc: 0.9661 - val_loss: 0.1499 - val_acc: 0.9581\n",
      "Epoch 14/90\n",
      "18064/18209 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9663\n",
      "Epoch 00014: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.1080 - acc: 0.9664 - val_loss: 0.1398 - val_acc: 0.9593\n",
      "Epoch 15/90\n",
      "18080/18209 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9657\n",
      "Epoch 00015: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.1042 - acc: 0.9659 - val_loss: 0.1325 - val_acc: 0.9600\n",
      "Epoch 16/90\n",
      "18176/18209 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9669\n",
      "Epoch 00016: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 169us/step - loss: 0.1011 - acc: 0.9669 - val_loss: 0.1336 - val_acc: 0.9623\n",
      "Epoch 17/90\n",
      "18080/18209 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9675\n",
      "Epoch 00017: val_loss improved from 0.12683 to 0.11674, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.1014 - acc: 0.9675 - val_loss: 0.1167 - val_acc: 0.9608\n",
      "Epoch 18/90\n",
      "18112/18209 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9686\n",
      "Epoch 00018: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0991 - acc: 0.9687 - val_loss: 0.1181 - val_acc: 0.9616\n",
      "Epoch 19/90\n",
      "18032/18209 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9676\n",
      "Epoch 00019: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 174us/step - loss: 0.0972 - acc: 0.9677 - val_loss: 0.1274 - val_acc: 0.9620\n",
      "Epoch 20/90\n",
      "17968/18209 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9697\n",
      "Epoch 00020: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 175us/step - loss: 0.0941 - acc: 0.9695 - val_loss: 0.1334 - val_acc: 0.9577\n",
      "Epoch 21/90\n",
      "17904/18209 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9691\n",
      "Epoch 00021: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 172us/step - loss: 0.0949 - acc: 0.9688 - val_loss: 0.1180 - val_acc: 0.9604\n",
      "Epoch 22/90\n",
      "18016/18209 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9700\n",
      "Epoch 00022: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0917 - acc: 0.9701 - val_loss: 0.1262 - val_acc: 0.9612\n",
      "Epoch 23/90\n",
      "18016/18209 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9709\n",
      "Epoch 00023: val_loss improved from 0.11674 to 0.11414, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 172us/step - loss: 0.0884 - acc: 0.9707 - val_loss: 0.1141 - val_acc: 0.9620\n",
      "Epoch 24/90\n",
      "18064/18209 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9717\n",
      "Epoch 00024: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0910 - acc: 0.9717 - val_loss: 0.1152 - val_acc: 0.9589\n",
      "Epoch 25/90\n",
      "18160/18209 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9719\n",
      "Epoch 00025: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0850 - acc: 0.9719 - val_loss: 0.1289 - val_acc: 0.9600\n",
      "Epoch 26/90\n",
      "17984/18209 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9711\n",
      "Epoch 00026: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0879 - acc: 0.9711 - val_loss: 0.1159 - val_acc: 0.9631\n",
      "Epoch 27/90\n",
      "18144/18209 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9711\n",
      "Epoch 00027: val_loss improved from 0.11414 to 0.11384, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0860 - acc: 0.9712 - val_loss: 0.1138 - val_acc: 0.9620\n",
      "Epoch 28/90\n",
      "18096/18209 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9718\n",
      "Epoch 00028: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0860 - acc: 0.9717 - val_loss: 0.1199 - val_acc: 0.9635\n",
      "Epoch 29/90\n",
      "18064/18209 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9713\n",
      "Epoch 00029: val_loss improved from 0.11384 to 0.11282, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0866 - acc: 0.9712 - val_loss: 0.1128 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/90\n",
      "18032/18209 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9718\n",
      "Epoch 00030: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0845 - acc: 0.9717 - val_loss: 0.1177 - val_acc: 0.9608\n",
      "Epoch 31/90\n",
      "18096/18209 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9728\n",
      "Epoch 00031: val_loss improved from 0.11282 to 0.11218, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0790 - acc: 0.9727 - val_loss: 0.1122 - val_acc: 0.9627\n",
      "Epoch 32/90\n",
      "18160/18209 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9735\n",
      "Epoch 00032: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 169us/step - loss: 0.0802 - acc: 0.9735 - val_loss: 0.1159 - val_acc: 0.9627\n",
      "Epoch 33/90\n",
      "18128/18209 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9734\n",
      "Epoch 00033: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0782 - acc: 0.9734 - val_loss: 0.1163 - val_acc: 0.9639\n",
      "Epoch 34/90\n",
      "18016/18209 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9732\n",
      "Epoch 00034: val_loss improved from 0.11218 to 0.11129, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 172us/step - loss: 0.0791 - acc: 0.9733 - val_loss: 0.1113 - val_acc: 0.9639\n",
      "Epoch 35/90\n",
      "18048/18209 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9735\n",
      "Epoch 00035: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0774 - acc: 0.9736 - val_loss: 0.1136 - val_acc: 0.9643\n",
      "Epoch 36/90\n",
      "18112/18209 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9735\n",
      "Epoch 00036: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0780 - acc: 0.9734 - val_loss: 0.1167 - val_acc: 0.9627\n",
      "Epoch 37/90\n",
      "18080/18209 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9747\n",
      "Epoch 00037: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0742 - acc: 0.9747 - val_loss: 0.1133 - val_acc: 0.9616\n",
      "Epoch 38/90\n",
      "18144/18209 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9743\n",
      "Epoch 00038: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0752 - acc: 0.9742 - val_loss: 0.1185 - val_acc: 0.9620\n",
      "Epoch 39/90\n",
      "18096/18209 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9746\n",
      "Epoch 00039: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0750 - acc: 0.9747 - val_loss: 0.1160 - val_acc: 0.9639\n",
      "Epoch 40/90\n",
      "18096/18209 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9762\n",
      "Epoch 00040: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0724 - acc: 0.9761 - val_loss: 0.1137 - val_acc: 0.9631\n",
      "Epoch 41/90\n",
      "18128/18209 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9756\n",
      "Epoch 00041: val_loss improved from 0.11129 to 0.10726, saving model to HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0717 - acc: 0.9757 - val_loss: 0.1073 - val_acc: 0.9658\n",
      "Epoch 42/90\n",
      "18048/18209 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9745\n",
      "Epoch 00042: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 174us/step - loss: 0.0721 - acc: 0.9742 - val_loss: 0.1147 - val_acc: 0.9639\n",
      "Epoch 43/90\n",
      "18096/18209 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9752\n",
      "Epoch 00043: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0719 - acc: 0.9752 - val_loss: 0.1118 - val_acc: 0.9654\n",
      "Epoch 44/90\n",
      "17936/18209 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9752\n",
      "Epoch 00044: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 175us/step - loss: 0.0718 - acc: 0.9752 - val_loss: 0.1122 - val_acc: 0.9631\n",
      "Epoch 45/90\n",
      "18048/18209 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9752\n",
      "Epoch 00045: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0703 - acc: 0.9753 - val_loss: 0.1165 - val_acc: 0.9627\n",
      "Epoch 46/90\n",
      "18080/18209 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9754\n",
      "Epoch 00046: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0688 - acc: 0.9755 - val_loss: 0.1135 - val_acc: 0.9654\n",
      "Epoch 47/90\n",
      "18144/18209 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9762\n",
      "Epoch 00047: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 169us/step - loss: 0.0698 - acc: 0.9761 - val_loss: 0.1130 - val_acc: 0.9639\n",
      "Epoch 48/90\n",
      "18032/18209 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9761\n",
      "Epoch 00048: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0696 - acc: 0.9762 - val_loss: 0.1138 - val_acc: 0.9643\n",
      "Epoch 49/90\n",
      "18160/18209 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9759\n",
      "Epoch 00049: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0700 - acc: 0.9760 - val_loss: 0.1197 - val_acc: 0.9643\n",
      "Epoch 50/90\n",
      "18080/18209 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9770\n",
      "Epoch 00050: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 170us/step - loss: 0.0675 - acc: 0.9771 - val_loss: 0.1224 - val_acc: 0.9623\n",
      "Epoch 51/90\n",
      "18000/18209 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9774\n",
      "Epoch 00051: val_loss did not improve\n",
      "18209/18209 [==============================] - 3s 171us/step - loss: 0.0644 - acc: 0.9774 - val_loss: 0.1145 - val_acc: 0.9646\n",
      "Epoch 00051: early stopping\n",
      "5200/5200 [==============================] - 0s 31us/step\n",
      "[0.098843745397081462, 0.96961538461538466]\n",
      "0.991438274262\n",
      "0.98540809721\n"
     ]
    }
   ],
   "source": [
    " adam = Adam(lr = 0.0001)\n",
    " model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    " print('running at most 60 epochs')\n",
    " checkpointer = ModelCheckpoint(filepath=\"HistoneMark_H3K9ac_TF_ncl_GM12878.hdf5\",verbose=1, monitor='val_loss',save_best_only=True)\n",
    " earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    " model.fit(X_train_H3K4me3, Y_train_H3K4me3, batch_size=16, epochs=90, shuffle=True, validation_data=( X_val_H3K4me3, Y_val_H3K4me3), callbacks=[checkpointer,earlystopper])\n",
    " #model.fit(X_train_s, Y_train_s, batch_size=12, epochs=50, shuffle=True, validation_data=( X_val_s, Y_val_s), callbacks=[checkpointer,earlystopper])\n",
    " y_pred = model.predict(X_test_H3K4me3)\n",
    " \n",
    " #np.savetxt('H3K27me3_true.csv', Y_test_H3K4me3, delimiter=\",\")\n",
    " #np.savetxt('H3K9ac_pred.csv', y_pred, delimiter=\",\")\n",
    " #y_pred = model.predict(X_test_s)\n",
    " #tresults = model.evaluate(X_test_s, Y_test_s)\n",
    " tresults = model.evaluate(X_test_H3K4me3, Y_test_H3K4me3)\n",
    " print(tresults)\n",
    " #model.summary()\n",
    " #print(roc_auc_score(Y_test_s,y_pred))\n",
    " print(roc_auc_score(Y_test_H3K4me3, y_pred))\n",
    " aupr = average_precision_score(Y_test_H3K4me3, y_pred)\n",
    " print(aupr)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 171.00 483.00\" width=\"171pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 167,-479 167,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140221984674064 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140221984674064</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 163,-474.5 163,-438.5 0,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-452.8\">dense_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140221984541968 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140221984541968</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-365.5 30.5,-401.5 132.5,-401.5 132.5,-365.5 30.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-379.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140221984674064&#45;&gt;140221984541968 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140221984674064-&gt;140221984541968</title>\n",
       "<path d=\"M81.5,-438.4551C81.5,-430.3828 81.5,-420.6764 81.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.0001,-411.5903 81.5,-401.5904 78.0001,-411.5904 85.0001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140221984673936 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140221984673936</title>\n",
       "<polygon fill=\"none\" points=\"19,-292.5 19,-328.5 144,-328.5 144,-292.5 19,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-306.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140221984541968&#45;&gt;140221984673936 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140221984541968-&gt;140221984673936</title>\n",
       "<path d=\"M81.5,-365.4551C81.5,-357.3828 81.5,-347.6764 81.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.0001,-338.5903 81.5,-328.5904 78.0001,-338.5904 85.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140221984674128 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140221984674128</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-219.5 30.5,-255.5 132.5,-255.5 132.5,-219.5 30.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-233.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140221984673936&#45;&gt;140221984674128 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140221984673936-&gt;140221984674128</title>\n",
       "<path d=\"M81.5,-292.4551C81.5,-284.3828 81.5,-274.6764 81.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.0001,-265.5903 81.5,-255.5904 78.0001,-265.5904 85.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140221984677328 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140221984677328</title>\n",
       "<polygon fill=\"none\" points=\"19,-146.5 19,-182.5 144,-182.5 144,-146.5 19,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-160.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 140221984674128&#45;&gt;140221984677328 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140221984674128-&gt;140221984677328</title>\n",
       "<path d=\"M81.5,-219.4551C81.5,-211.3828 81.5,-201.6764 81.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.0001,-192.5903 81.5,-182.5904 78.0001,-192.5904 85.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140221984331984 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140221984331984</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-73.5 30.5,-109.5 132.5,-109.5 132.5,-73.5 30.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-87.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140221984677328&#45;&gt;140221984331984 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140221984677328-&gt;140221984331984</title>\n",
       "<path d=\"M81.5,-146.4551C81.5,-138.3828 81.5,-128.6764 81.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.0001,-119.5903 81.5,-109.5904 78.0001,-119.5904 85.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140221984332304 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140221984332304</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-.5 30.5,-36.5 132.5,-36.5 132.5,-.5 30.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-14.8\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 140221984331984&#45;&gt;140221984332304 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140221984331984-&gt;140221984332304</title>\n",
       "<path d=\"M81.5,-73.4551C81.5,-65.3828 81.5,-55.6764 81.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.0001,-46.5903 81.5,-36.5904 78.0001,-46.5904 85.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='model_H1_TF_H3K4me3.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_H3K4me3_lr = pd.read_csv('H3K27me3_lr_true.csv')\n",
    "Y_test_H3K4me3_lr = Y_test_H3K4me3_lr.values\n",
    "y_pred_lr = pd.read_csv('H3K27me3_lr_pred.csv')\n",
    "y_pred_lr = y_pred_lr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801568280998\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde3410f650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(Y_test_H3K4me3, y_pred)\n",
    "pr_auc = aupr\n",
    "print(pr_auc)\n",
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve(Y_test_H3K4me3_lr, y_pred_lr)\n",
    "pr_auc_lr = average_precision_score(Y_test_H3K4me3_lr, y_pred_lr)\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.plot(recall, precision, 'b', label = 'AUC = %0.2f' % pr_auc)\n",
    "plt.plot(recall_lr, precision_lr, 'g', label = 'AUC = %0.2f' % pr_auc_lr)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2957   40]\n",
      " [  63 2309]]\n"
     ]
    }
   ],
   "source": [
    " y_pred = (y_pred>0.5)\n",
    " cm = confusion_matrix(Y_test_H3K4me3, y_pred)\n",
    " print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
