{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "import six\n",
    "import csv\n",
    "from six.moves import range\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop,Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import  Dropout, Activation, Flatten\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from keras.constraints import maxnorm\n",
    "#from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, LSTM, Bidirectional\n",
    "#from keras.utils import plot_model\n",
    "#from keras.utils.layer_utils import print_layer_shapes\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26262, 2080)\n",
      "(26262,)\n"
     ]
    }
   ],
   "source": [
    "h5filename = \"histonemodKmer_resample_ncl.h5\"\n",
    "h5file = h5.File(h5filename,'r')\n",
    "input_features = h5file['input/H3K27me3_kmer_1000']\n",
    "output_H3K27me3 = h5file['output/H3K27me3_1000']\n",
    "input_features = np.array(input_features,dtype='int8')\n",
    "output_H3K27me3 = np.array(output_H3K27me3, dtype='int8')\n",
    "print(input_features.shape)\n",
    "print(output_H3K27me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[    0     8    41 ..., 26196 26217 26239]\n",
      "(26262, 2081)\n",
      "(2470, 1)\n",
      "(23792, 1)\n",
      "(2470, 2081)\n",
      "(23792, 2081)\n",
      "[[ 2  1  2 ...,  1  0  0]\n",
      " [11  1  3 ...,  2  2  0]\n",
      " [ 1  2  3 ...,  0  0  1]\n",
      " ..., \n",
      " [ 3  2  6 ...,  3  0  1]\n",
      " [ 0  1  2 ...,  2  0  1]\n",
      " [24  1  4 ...,  1  0  5]]\n"
     ]
    }
   ],
   "source": [
    "output_H3K27me3_reshape = output_H3K27me3.reshape(len(output_H3K27me3),1)\n",
    "#combine the label with input dna\n",
    "input_features_label = np.concatenate((input_features,output_H3K27me3_reshape), axis=1)\n",
    "H3K27me3_df = pd.DataFrame(output_H3K27me3)\n",
    "pos_label= H3K27me3_df.loc[H3K27me3_df.iloc[:,0]==1]\n",
    "pos_label_ix = np.array(pos_label.index)\n",
    "neg_label = H3K27me3_df.loc[H3K27me3_df.iloc[:,0]==0]\n",
    "neg_label_ix = np.array(neg_label.index)\n",
    "pos_sam_H3K27me3 = input_features_label[pos_label_ix,:]\n",
    "neg_sam_H3K27me3 = input_features_label[neg_label_ix,:]\n",
    "print('here')\n",
    "print(pos_label_ix)\n",
    "print(input_features_label.shape)\n",
    "print(pos_label.shape)\n",
    "print(neg_label.shape)\n",
    "print(pos_sam_H3K27me3.shape)\n",
    "print(neg_sam_H3K27me3.shape)\n",
    "print(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16655  1729]\n",
      "(18384, 2080)\n",
      "(18384,)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_neg_H3K27me3 = neg_sam_H3K27me3[0:16655,:]\n",
    "train_pos_H3K27me3 = pos_sam_H3K27me3[0:1729,:]\n",
    "train_neg_pos_H3K27me3 = np.concatenate((train_neg_H3K27me3, train_pos_H3K27me3),axis = 0)\n",
    "np.random.shuffle(train_neg_pos_H3K27me3)\n",
    "X_train_H3K27me3 = train_neg_pos_H3K27me3[:,0:2080]\n",
    "Y_train_H3K27me3 = train_neg_pos_H3K27me3[:,2080]\n",
    "frq = np.bincount(Y_train_H3K27me3)\n",
    "print(frq)\n",
    "print(X_train_H3K27me3.shape)\n",
    "print(Y_train_H3K27me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2626  247]\n",
      "(2873, 2080)\n",
      "(2873,)\n"
     ]
    }
   ],
   "source": [
    "#val\n",
    "val_neg_H3K27me3 = neg_sam_H3K27me3[16655:19281:]\n",
    "val_pos_H3K27me3 = pos_sam_H3K27me3 [1729:1976,:]\n",
    "val_neg_pos_H3K27me3 = np.concatenate((val_neg_H3K27me3, val_pos_H3K27me3),axis = 0)\n",
    "np.random.shuffle(val_neg_pos_H3K27me3)\n",
    "X_val_H3K27me3 = val_neg_pos_H3K27me3[:,0:2080]\n",
    "Y_val_H3K27me3 = val_neg_pos_H3K27me3[:,2080]\n",
    "frq = np.bincount(Y_val_H3K27me3)\n",
    "print(frq)\n",
    "print(X_val_H3K27me3.shape)\n",
    "print(Y_val_H3K27me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4511  494]\n",
      "(5005, 2080)\n",
      "(5005,)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_neg_H3K27me3 = neg_sam_H3K27me3[19281:,:]\n",
    "test_pos_H3K27me3 = pos_sam_H3K27me3 [1976:,:]\n",
    "test_neg_pos_H3K27me3 = np.concatenate((test_neg_H3K27me3, test_pos_H3K27me3),axis = 0)\n",
    "np.random.shuffle(test_neg_pos_H3K27me3)\n",
    "X_test_H3K27me3 = test_neg_pos_H3K27me3[:,0:2080]\n",
    "Y_test_H3K27me3 = test_neg_pos_H3K27me3[:,2080]\n",
    "frq = np.bincount(Y_test_H3K27me3)\n",
    "print(frq)\n",
    "print(X_test_H3K27me3.shape)\n",
    "print(Y_test_H3K27me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"H3K27me3_ncl_test\": shape (5263,), type \"|i1\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5filename = \"histonemodKmer_resample_nclx.h5\"\n",
    "h5file = h5.File(h5filename,'a')\n",
    "h5file.create_dataset('/input/H3K27me3_ncl_train',data=X_train_H3K27me3, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/input/H3K27me3_ncl_val', data=X_val_H3K27me3, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/input/H3K27me3_ncl_test', data=X_test_H3K27me3, dtype =np.int8, compression ='gzip')\n",
    "\n",
    "h5file.create_dataset('/output/H3K27me3_ncl_train',data = Y_train_H3K27me3, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/output/H3K27me3_ncl_val', data = Y_val_H3K27me3, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/output/H3K27me3_ncl_test', data = Y_test_H3K27me3, dtype =np.int8, compression ='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26309,)\n",
      "[111 112 113 114 116 117 118 119 120 121 122 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 152 153 154 155 157 158 159 160 161 162 163 164]\n"
     ]
    }
   ],
   "source": [
    "h5filename = \"histonemodKmer_resample_nclx.h5\"\n",
    "h5file = h5.File(h5filename,'r')\n",
    "idx = h5file['output/H3K27me3_idx']\n",
    "idx = np.array(idx)\n",
    "print(idx.shape)\n",
    "print(idx[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1065472   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 180)               92340     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                12670     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 1,170,553\n",
      "Trainable params: 1,170,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model = Sequential()\n",
    " #model.add(Conv1D(activation=\"relu\", input_shape=(2080, 1), padding=\"valid\", strides=1, filters=256, kernel_size=11, kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.001)))\n",
    " #model.add(MaxPooling1D(pool_size=4))\n",
    " #model.add(Dropout(0.6))\n",
    " #model.add(Conv1D(activation=\"relu\", padding=\"valid\", strides=1, filters=640, kernel_size=3, kernel_initializer='glorot_uniform', kernel_regularizer=l2(0.001)))\n",
    " #model.add(MaxPooling1D(pool_size=2))\n",
    " #model.add(Dropout(0.5))\n",
    " #model.add(Flatten())\n",
    " #model.summary()\n",
    " model.add(Dense(units=512, input_dim=2080, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    " model.add(Dropout(0.5))\n",
    " #model.add(Dense(units=512, input_dim=512,  activation=\"relu\", kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.001)))\n",
    " #model.add(Dropout(0.5))\n",
    " model.add(Dense(units=180, activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(units=70, activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    " model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running at most 60 epochs\n",
      "Train on 18384 samples, validate on 2873 samples\n",
      "Epoch 1/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.8900\n",
      "Epoch 00001: val_loss improved from inf to 0.25377, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 8s 428us/step - loss: 0.3141 - acc: 0.8901 - val_loss: 0.2538 - val_acc: 0.9119\n",
      "Epoch 2/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.9012\n",
      "Epoch 00002: val_loss improved from 0.25377 to 0.24958, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 374us/step - loss: 0.2590 - acc: 0.9013 - val_loss: 0.2496 - val_acc: 0.9165\n",
      "Epoch 3/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9036\n",
      "Epoch 00003: val_loss improved from 0.24958 to 0.22831, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 363us/step - loss: 0.2453 - acc: 0.9036 - val_loss: 0.2283 - val_acc: 0.9161\n",
      "Epoch 4/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.2333 - acc: 0.9082\n",
      "Epoch 00004: val_loss improved from 0.22831 to 0.22221, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 373us/step - loss: 0.2331 - acc: 0.9082 - val_loss: 0.2222 - val_acc: 0.9186\n",
      "Epoch 5/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.2253 - acc: 0.9088\n",
      "Epoch 00005: val_loss improved from 0.22221 to 0.21388, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 374us/step - loss: 0.2251 - acc: 0.9088 - val_loss: 0.2139 - val_acc: 0.9217\n",
      "Epoch 6/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9164- ETA: 1s - loss: 0.21\n",
      "Epoch 00006: val_loss improved from 0.21388 to 0.20614, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 368us/step - loss: 0.2131 - acc: 0.9161 - val_loss: 0.2061 - val_acc: 0.9227\n",
      "Epoch 7/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9160\n",
      "Epoch 00007: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 377us/step - loss: 0.2083 - acc: 0.9160 - val_loss: 0.2063 - val_acc: 0.9238\n",
      "Epoch 8/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9193\n",
      "Epoch 00008: val_loss improved from 0.20614 to 0.20171, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 375us/step - loss: 0.2008 - acc: 0.9193 - val_loss: 0.2017 - val_acc: 0.9238\n",
      "Epoch 9/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9203\n",
      "Epoch 00009: val_loss improved from 0.20171 to 0.19538, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 372us/step - loss: 0.1943 - acc: 0.9204 - val_loss: 0.1954 - val_acc: 0.9234\n",
      "Epoch 10/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9254\n",
      "Epoch 00010: val_loss improved from 0.19538 to 0.18771, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 375us/step - loss: 0.1853 - acc: 0.9249 - val_loss: 0.1877 - val_acc: 0.9238\n",
      "Epoch 11/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9265\n",
      "Epoch 00011: val_loss improved from 0.18771 to 0.18498, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 381us/step - loss: 0.1783 - acc: 0.9266 - val_loss: 0.1850 - val_acc: 0.9224\n",
      "Epoch 12/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9294\n",
      "Epoch 00012: val_loss improved from 0.18498 to 0.18426, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 380us/step - loss: 0.1719 - acc: 0.9292 - val_loss: 0.1843 - val_acc: 0.9279\n",
      "Epoch 13/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9313\n",
      "Epoch 00013: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 377us/step - loss: 0.1644 - acc: 0.9312 - val_loss: 0.1854 - val_acc: 0.9234\n",
      "Epoch 14/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9348\n",
      "Epoch 00014: val_loss improved from 0.18426 to 0.18281, saving model to HistoneMark_H3K27me3.hdf5\n",
      "18384/18384 [==============================] - 7s 381us/step - loss: 0.1576 - acc: 0.9349 - val_loss: 0.1828 - val_acc: 0.9279\n",
      "Epoch 15/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9382\n",
      "Epoch 00015: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 380us/step - loss: 0.1514 - acc: 0.9378 - val_loss: 0.1846 - val_acc: 0.9262\n",
      "Epoch 16/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9417\n",
      "Epoch 00016: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 382us/step - loss: 0.1410 - acc: 0.9419 - val_loss: 0.1863 - val_acc: 0.9255\n",
      "Epoch 17/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9466\n",
      "Epoch 00017: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 382us/step - loss: 0.1294 - acc: 0.9466 - val_loss: 0.1893 - val_acc: 0.9276\n",
      "Epoch 18/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9491\n",
      "Epoch 00018: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 367us/step - loss: 0.1273 - acc: 0.9492 - val_loss: 0.1872 - val_acc: 0.9262\n",
      "Epoch 19/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9524\n",
      "Epoch 00019: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 363us/step - loss: 0.1156 - acc: 0.9523 - val_loss: 0.1974 - val_acc: 0.9276\n",
      "Epoch 20/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9575\n",
      "Epoch 00020: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 363us/step - loss: 0.1049 - acc: 0.9575 - val_loss: 0.2065 - val_acc: 0.9217\n",
      "Epoch 21/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9627\n",
      "Epoch 00021: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 369us/step - loss: 0.0957 - acc: 0.9625 - val_loss: 0.2126 - val_acc: 0.9297\n",
      "Epoch 22/50\n",
      "18176/18384 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9659\n",
      "Epoch 00022: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 373us/step - loss: 0.0865 - acc: 0.9659 - val_loss: 0.2173 - val_acc: 0.9290\n",
      "Epoch 23/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9696\n",
      "Epoch 00023: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 379us/step - loss: 0.0775 - acc: 0.9696 - val_loss: 0.2235 - val_acc: 0.9307\n",
      "Epoch 24/50\n",
      "18304/18384 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9714\n",
      "Epoch 00024: val_loss did not improve\n",
      "18384/18384 [==============================] - 7s 391us/step - loss: 0.0734 - acc: 0.9715 - val_loss: 0.2415 - val_acc: 0.9297\n",
      "Epoch 00024: early stopping\n",
      "5005/5005 [==============================] - 1s 186us/step\n",
      "[0.29054456392189604, 0.92007992009182915]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1065472   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 180)               92340     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                12670     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 1,170,553\n",
      "Trainable params: 1,170,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897145708601\n",
      "0.558811141655\n",
      "[[4395  116]\n",
      " [ 284  210]]\n"
     ]
    }
   ],
   "source": [
    " adam = Adam(lr=0.0001)\n",
    " sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    " model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    " print('running at most 60 epochs')\n",
    " checkpointer = ModelCheckpoint(filepath=\"HistoneMark_H3K27me3.hdf5\", verbose=1, save_best_only=True)\n",
    " earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    " model.fit(X_train_H3K27me3, Y_train_H3K27me3, batch_size=128, epochs=50, shuffle=True, validation_data=( X_val_H3K27me3, Y_val_H3K27me3), callbacks=[checkpointer,earlystopper])\n",
    " #model.fit(X_train_s, Y_train_s, batch_size=12, epochs=50, shuffle=True, validation_data=( X_val_s, Y_val_s), callbacks=[checkpointer,earlystopper])\n",
    " y_pred = model.predict(X_test_H3K27me3)\n",
    " #y_pred = model.predict(X_test_s)\n",
    " #tresults = model.evaluate(X_test_s, Y_test_s)\n",
    " np.savetxt('H3K27me3_true.csv', Y_test_H3K27me3, delimiter=\",\")\n",
    " np.savetxt('H3K27me3_pred.csv', y_pred, delimiter=\",\")\n",
    " tresults = model.evaluate(X_test_H3K27me3, Y_test_H3K27me3)\n",
    " print(tresults)\n",
    " model.summary()\t\t\n",
    " #print(roc_auc_score(Y_test_s,y_pred))\n",
    " print(roc_auc_score(Y_test_H3K27me3, y_pred))\n",
    " print(average_precision_score(Y_test_H3K27me3, y_pred))\n",
    " y_pred = (y_pred>0.5)\n",
    " cm = confusion_matrix(Y_test_H3K27me3, y_pred)\n",
    " print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
