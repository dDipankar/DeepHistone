{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "import six\n",
    "import csv\n",
    "from six.moves import range\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop,Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import  Dropout, Activation, Flatten\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from keras.constraints import maxnorm\n",
    "#from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, LSTM, Bidirectional\n",
    "#from keras.utils import plot_model\n",
    "#from keras.utils.layer_utils import print_layer_shapes\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5filename = \"histonemodKmer_resample_ncl_GM12878.h5\"\n",
    "h5file = h5.File(h5filename,'r')\n",
    "input_features = h5file['input/H3K4me3_kmer_2000']\n",
    "output_H3K4me3 = h5file['output/H3K4me3_2000']\n",
    "input_features = np.array(input_features,dtype='int8')\n",
    "output_H3K4me3 = np.array(output_H3K4me3, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[    0     4     6 ..., 23643 23647 23651]\n",
      "(23652, 2081)\n",
      "(9150, 1)\n",
      "(14502, 1)\n",
      "(9150, 2081)\n",
      "(14502, 2081)\n",
      "[[44  4  6 ...,  2  2  1]\n",
      " [21  8  9 ..., 12  0  7]\n",
      " [13  6 16 ...,  7  2  5]\n",
      " ..., \n",
      " [15  5 10 ...,  1  2  5]\n",
      " [17  4  5 ...,  3  1  6]\n",
      " [22  9 10 ...,  4  1  6]]\n"
     ]
    }
   ],
   "source": [
    "output_H3K4me3_reshape = output_H3K4me3.reshape(len(output_H3K4me3),1)\n",
    "#combine the label with input dna\n",
    "input_features_label = np.concatenate((input_features,output_H3K4me3_reshape), axis=1)\n",
    "H3K4me3_df = pd.DataFrame(output_H3K4me3)\n",
    "pos_label= H3K4me3_df.loc[H3K4me3_df.iloc[:,0]==1]\n",
    "pos_label_ix = np.array(pos_label.index)\n",
    "neg_label = H3K4me3_df.loc[H3K4me3_df.iloc[:,0]==0]\n",
    "neg_label_ix = np.array(neg_label.index)\n",
    "pos_sam_H3K4me3 = input_features_label[pos_label_ix,:]\n",
    "neg_sam_H3K4me3 = input_features_label[neg_label_ix,:]\n",
    "np.random.shuffle(pos_sam_H3K4me3)\n",
    "np.random.shuffle(neg_sam_H3K4me3)\n",
    "print('here')\n",
    "print(pos_label_ix)\n",
    "print(input_features_label.shape)\n",
    "print(pos_label.shape)\n",
    "print(neg_label.shape)\n",
    "print(pos_sam_H3K4me3.shape)\n",
    "print(neg_sam_H3K4me3.shape)\n",
    "print(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10151  6405]\n",
      "(16556, 2080)\n",
      "(16556,)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_sample_neg = int(neg_sam_H3K4me3.shape[0] * 0.7)\n",
    "train_sample_pos = int(pos_sam_H3K4me3.shape[0] * 0.7)\n",
    "train_neg_H3K4me3 = neg_sam_H3K4me3[0:train_sample_neg,:]\n",
    "train_pos_H3K4me3 = pos_sam_H3K4me3[0:train_sample_pos,:]\n",
    "train_neg_pos_H3K4me3 = np.concatenate((train_neg_H3K4me3, train_pos_H3K4me3),axis = 0)\n",
    "np.random.shuffle(train_neg_pos_H3K4me3)\n",
    "X_train_H3K4me3 = train_neg_pos_H3K4me3[:,0:2080]\n",
    "Y_train_H3K4me3 = train_neg_pos_H3K4me3[:,2080]\n",
    "frq = np.bincount(Y_train_H3K4me3)\n",
    "print(frq)\n",
    "print(X_train_H3K4me3.shape)\n",
    "print(Y_train_H3K4me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450  915]\n",
      "(2365, 2080)\n",
      "(2365,)\n"
     ]
    }
   ],
   "source": [
    "#val\n",
    "val_sample_neg = train_sample_neg + int(neg_sam_H3K4me3.shape[0]*0.1)\n",
    "val_sample_pos = train_sample_pos + int(pos_sam_H3K4me3.shape[0]*0.1)\n",
    "val_neg_H3K4me3 = neg_sam_H3K4me3[train_sample_neg:val_sample_neg,:]\n",
    "val_pos_H3K4me3 = pos_sam_H3K4me3 [train_sample_pos:val_sample_pos,:]\n",
    "val_neg_pos_H3K4me3 = np.concatenate((val_neg_H3K4me3, val_pos_H3K4me3),axis = 0)\n",
    "np.random.shuffle(val_neg_pos_H3K4me3)\n",
    "X_val_H3K4me3 = val_neg_pos_H3K4me3[:,0:2080]\n",
    "Y_val_H3K4me3 = val_neg_pos_H3K4me3[:,2080]\n",
    "frq = np.bincount(Y_val_H3K4me3)\n",
    "print(frq)\n",
    "print(X_val_H3K4me3.shape)\n",
    "print(Y_val_H3K4me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2901 1830]\n",
      "(4731, 2080)\n",
      "(4731,)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_neg_H3K4me3 = neg_sam_H3K4me3[val_sample_neg:,:]\n",
    "test_pos_H3K4me3 = pos_sam_H3K4me3 [val_sample_pos:,:]\n",
    "test_neg_pos_H3K4me3 = np.concatenate((test_neg_H3K4me3, test_pos_H3K4me3),axis = 0)\n",
    "np.random.shuffle(test_neg_pos_H3K4me3)\n",
    "X_test_H3K4me3 = test_neg_pos_H3K4me3[:,0:2080]\n",
    "Y_test_H3K4me3 = test_neg_pos_H3K4me3[:,2080]\n",
    "frq = np.bincount(Y_test_H3K4me3)\n",
    "print(frq)\n",
    "print(X_test_H3K4me3.shape)\n",
    "print(Y_test_H3K4me3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 512)               1065472   \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 180)               92340     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 70)                12670     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 1,170,553\n",
      "Trainable params: 1,170,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model = Sequential()\n",
    " #model.add(Conv1D(activation=\"relu\", input_shape=(2080, 1), padding=\"valid\", strides=1, filters=256, kernel_size=11, kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.001)))\n",
    " #model.add(MaxPooling1D(pool_size=4))\n",
    " #model.add(Dropout(0.6))\n",
    " #model.add(Conv1D(activation=\"relu\", padding=\"valid\", strides=1, filters=640, kernel_size=3, kernel_initializer='glorot_uniform', kernel_regularizer=l2(0.001)))\n",
    " #model.add(MaxPooling1D(pool_size=2))\n",
    " #model.add(Dropout(0.5))\n",
    " #model.add(Flatten())\n",
    " #model.summary()\n",
    " model.add(Dense(units=512, input_dim=2080, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    " model.add(Dropout(0.5))\n",
    " #model.add(Dense(units=512, input_dim=512,  activation=\"relu\", kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.001)))\n",
    " #model.add(Dropout(0.5))\n",
    " model.add(Dense(units=180, activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(units=70, activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    " model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running at most 60 epochs\n",
      "Train on 16556 samples, validate on 2365 samples\n",
      "Epoch 1/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.6440 - acc: 0.7164\n",
      "Epoch 00001: val_loss improved from inf to 0.36314, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 4s 261us/step - loss: 0.6433 - acc: 0.7167 - val_loss: 0.3631 - val_acc: 0.8677\n",
      "Epoch 2/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.4422 - acc: 0.8182\n",
      "Epoch 00002: val_loss improved from 0.36314 to 0.32867, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 143us/step - loss: 0.4417 - acc: 0.8187 - val_loss: 0.3287 - val_acc: 0.8727\n",
      "Epoch 3/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.3948 - acc: 0.8446\n",
      "Epoch 00003: val_loss improved from 0.32867 to 0.30063, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 142us/step - loss: 0.3951 - acc: 0.8445 - val_loss: 0.3006 - val_acc: 0.8879\n",
      "Epoch 4/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.3667 - acc: 0.8588\n",
      "Epoch 00004: val_loss improved from 0.30063 to 0.29303, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 143us/step - loss: 0.3671 - acc: 0.8582 - val_loss: 0.2930 - val_acc: 0.8909\n",
      "Epoch 5/50\n",
      "16128/16556 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.8628\n",
      "Epoch 00005: val_loss improved from 0.29303 to 0.28371, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 143us/step - loss: 0.3539 - acc: 0.8630 - val_loss: 0.2837 - val_acc: 0.8918\n",
      "Epoch 6/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.3422 - acc: 0.8677\n",
      "Epoch 00006: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 140us/step - loss: 0.3404 - acc: 0.8686 - val_loss: 0.2897 - val_acc: 0.8947\n",
      "Epoch 7/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.8725\n",
      "Epoch 00007: val_loss improved from 0.28371 to 0.27194, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 143us/step - loss: 0.3271 - acc: 0.8726 - val_loss: 0.2719 - val_acc: 0.9002\n",
      "Epoch 8/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.8749\n",
      "Epoch 00008: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 143us/step - loss: 0.3168 - acc: 0.8748 - val_loss: 0.2725 - val_acc: 0.8989\n",
      "Epoch 9/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.3112 - acc: 0.8779\n",
      "Epoch 00009: val_loss improved from 0.27194 to 0.26345, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.3114 - acc: 0.8777 - val_loss: 0.2634 - val_acc: 0.9002\n",
      "Epoch 10/50\n",
      "16128/16556 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.8789\n",
      "Epoch 00010: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 140us/step - loss: 0.3058 - acc: 0.8794 - val_loss: 0.2639 - val_acc: 0.9044\n",
      "Epoch 11/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.3005 - acc: 0.8839\n",
      "Epoch 00011: val_loss improved from 0.26345 to 0.25791, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 145us/step - loss: 0.3009 - acc: 0.8837 - val_loss: 0.2579 - val_acc: 0.9011\n",
      "Epoch 12/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.8845\n",
      "Epoch 00012: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.2930 - acc: 0.8845 - val_loss: 0.2602 - val_acc: 0.9040\n",
      "Epoch 13/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.8912\n",
      "Epoch 00013: val_loss improved from 0.25791 to 0.25695, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 145us/step - loss: 0.2823 - acc: 0.8915 - val_loss: 0.2570 - val_acc: 0.9044\n",
      "Epoch 14/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.8923\n",
      "Epoch 00014: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.2784 - acc: 0.8928 - val_loss: 0.2621 - val_acc: 0.9044\n",
      "Epoch 15/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.2745 - acc: 0.8927\n",
      "Epoch 00015: val_loss improved from 0.25695 to 0.25474, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 146us/step - loss: 0.2742 - acc: 0.8928 - val_loss: 0.2547 - val_acc: 0.9032\n",
      "Epoch 16/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.8945\n",
      "Epoch 00016: val_loss improved from 0.25474 to 0.25274, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 146us/step - loss: 0.2704 - acc: 0.8947 - val_loss: 0.2527 - val_acc: 0.9066\n",
      "Epoch 17/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.2611 - acc: 0.9007\n",
      "Epoch 00017: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.2611 - acc: 0.9003 - val_loss: 0.2531 - val_acc: 0.9091\n",
      "Epoch 18/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.2575 - acc: 0.8997\n",
      "Epoch 00018: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.2572 - acc: 0.8994 - val_loss: 0.2595 - val_acc: 0.9082\n",
      "Epoch 19/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.9022\n",
      "Epoch 00019: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.2545 - acc: 0.9021 - val_loss: 0.2588 - val_acc: 0.9099\n",
      "Epoch 20/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9027\n",
      "Epoch 00020: val_loss improved from 0.25274 to 0.25176, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 146us/step - loss: 0.2470 - acc: 0.9030 - val_loss: 0.2518 - val_acc: 0.9053\n",
      "Epoch 21/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9067\n",
      "Epoch 00021: val_loss improved from 0.25176 to 0.25174, saving model to HistoneMark_H3K9ac_K562.hdf5\n",
      "16556/16556 [==============================] - 2s 145us/step - loss: 0.2386 - acc: 0.9064 - val_loss: 0.2517 - val_acc: 0.9057\n",
      "Epoch 22/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9098\n",
      "Epoch 00022: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 145us/step - loss: 0.2346 - acc: 0.9099 - val_loss: 0.2552 - val_acc: 0.9057\n",
      "Epoch 23/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9122\n",
      "Epoch 00023: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 145us/step - loss: 0.2288 - acc: 0.9122 - val_loss: 0.2541 - val_acc: 0.9049\n",
      "Epoch 24/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9141\n",
      "Epoch 00024: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 144us/step - loss: 0.2232 - acc: 0.9142 - val_loss: 0.2558 - val_acc: 0.9057\n",
      "Epoch 25/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9171\n",
      "Epoch 00025: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 141us/step - loss: 0.2154 - acc: 0.9167 - val_loss: 0.2573 - val_acc: 0.9082\n",
      "Epoch 26/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9167- ETA: 0s - loss: 0.2150 - a\n",
      "Epoch 00026: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 140us/step - loss: 0.2121 - acc: 0.9168 - val_loss: 0.2573 - val_acc: 0.9070\n",
      "Epoch 27/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9207\n",
      "Epoch 00027: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 141us/step - loss: 0.2052 - acc: 0.9207 - val_loss: 0.2577 - val_acc: 0.9070\n",
      "Epoch 28/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9258\n",
      "Epoch 00028: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 142us/step - loss: 0.1929 - acc: 0.9261 - val_loss: 0.2606 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "16256/16556 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9257\n",
      "Epoch 00029: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 137us/step - loss: 0.1888 - acc: 0.9260 - val_loss: 0.2627 - val_acc: 0.9061\n",
      "Epoch 30/50\n",
      "16512/16556 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9287\n",
      "Epoch 00030: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 136us/step - loss: 0.1822 - acc: 0.9288 - val_loss: 0.2615 - val_acc: 0.9023\n",
      "Epoch 31/50\n",
      "16384/16556 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9312\n",
      "Epoch 00031: val_loss did not improve\n",
      "16556/16556 [==============================] - 2s 137us/step - loss: 0.1741 - acc: 0.9310 - val_loss: 0.2710 - val_acc: 0.9044\n",
      "Epoch 00031: early stopping\n",
      "4731/4731 [==============================] - 0s 74us/step\n",
      "[0.28756740965820021, 0.89410272660806756]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 512)               1065472   \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 180)               92340     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 70)                12670     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 1,170,553\n",
      "Trainable params: 1,170,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.950078265833\n",
      "0.931989814856\n",
      "[[2740  161]\n",
      " [ 340 1490]]\n"
     ]
    }
   ],
   "source": [
    " adam = Adam(lr=0.0001)\n",
    " sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    " model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    " print('running at most 60 epochs')\n",
    " checkpointer = ModelCheckpoint(filepath=\"HistoneMark_H3K9ac_K562.hdf5\", verbose=1, save_best_only=True)\n",
    " earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    " model.fit(X_train_H3K4me3, Y_train_H3K4me3, batch_size=128, epochs=50, shuffle=True, validation_data=( X_val_H3K4me3, Y_val_H3K4me3), callbacks=[checkpointer,earlystopper])\n",
    " #model.fit(X_train_s, Y_train_s, batch_size=12, epochs=50, shuffle=True, validation_data=( X_val_s, Y_val_s), callbacks=[checkpointer,earlystopper])\n",
    " y_pred = model.predict(X_test_H3K4me3)\n",
    " #np.savetxt('H3K27ac_true.csv', Y_test_H3K4me3, delimiter=\",\")\n",
    " #np.savetxt('H3K27ac_pred.csv', y_pred, delimiter=\",\")\n",
    " #y_pred = model.predict(X_test_s)\n",
    " #tresults = model.evaluate(X_test_s, Y_test_s)\n",
    " tresults = model.evaluate(X_test_H3K4me3, Y_test_H3K4me3)\n",
    " print(tresults)\n",
    " model.summary()\n",
    " #print(roc_auc_score(Y_test_s,y_pred))\n",
    " print(roc_auc_score(Y_test_H3K4me3, y_pred))\n",
    " print(average_precision_score(Y_test_H3K4me3, y_pred))\n",
    " y_pred = (y_pred>0.5)\n",
    " cm = confusion_matrix(Y_test_H3K4me3, y_pred)\n",
    " print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
