{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "import six\n",
    "import csv\n",
    "from six.moves import range\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop,Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import  Dropout, Activation, Flatten\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from keras.constraints import maxnorm\n",
    "#from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, LSTM, Bidirectional\n",
    "#from keras.utils import plot_model\n",
    "#from keras.utils.layer_utils import print_layer_shapes\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23634, 2080)\n",
      "(23634,)\n"
     ]
    }
   ],
   "source": [
    "h5filename = \"histonemodKmer_resample_ncl_K562.h5\"\n",
    "h5file = h5.File(h5filename,'r')\n",
    "input_features = h5file['input/H3K27ac_kmer_2000']\n",
    "output_H3K27ac = h5file['output/H3K27ac_2000']\n",
    "input_features = np.array(input_features,dtype='int8')\n",
    "output_H3K27ac = np.array(output_H3K27ac, dtype='int8')\n",
    "print(input_features.shape)\n",
    "print(output_H3K27ac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[    0     5     6 ..., 23624 23628 23632]\n",
      "(23634, 2081)\n",
      "(8231, 1)\n",
      "(15403, 1)\n",
      "(8231, 2081)\n",
      "(15403, 2081)\n",
      "[[22  4  5 ...,  5  0  2]\n",
      " [19  9  8 ...,  7  1  4]\n",
      " [46  5  8 ...,  9  1  6]\n",
      " ..., \n",
      " [19  2  5 ...,  5  0  3]\n",
      " [50  5  6 ...,  4  0  0]\n",
      " [12  3  7 ...,  3  2  1]]\n"
     ]
    }
   ],
   "source": [
    "output_H3K27ac_reshape = output_H3K27ac.reshape(len(output_H3K27ac),1)\n",
    "#combine the label with input dna\n",
    "input_features_label = np.concatenate((input_features,output_H3K27ac_reshape), axis=1)\n",
    "H3K27ac_df = pd.DataFrame(output_H3K27ac)\n",
    "pos_label= H3K27ac_df.loc[H3K27ac_df.iloc[:,0]==1]\n",
    "pos_label_ix = np.array(pos_label.index)\n",
    "neg_label = H3K27ac_df.loc[H3K27ac_df.iloc[:,0]==0]\n",
    "neg_label_ix = np.array(neg_label.index)\n",
    "pos_sam_H3K27ac = input_features_label[pos_label_ix,:]\n",
    "neg_sam_H3K27ac = input_features_label[neg_label_ix,:]\n",
    "print('here')\n",
    "print(pos_label_ix)\n",
    "print(input_features_label.shape)\n",
    "print(pos_label.shape)\n",
    "print(neg_label.shape)\n",
    "print(pos_sam_H3K27ac.shape)\n",
    "print(neg_sam_H3K27ac.shape)\n",
    "print(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10782  5761]\n",
      "(16543, 2080)\n",
      "(16543,)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_neg_sample = int(neg_sam_H3K27ac.shape[0] * 0.7)\n",
    "train_pos_sample = int(pos_sam_H3K27ac.shape[0] * 0.7)\n",
    "train_neg_H3K27ac = neg_sam_H3K27ac[0:train_neg_sample,:]\n",
    "train_pos_H3K27ac = pos_sam_H3K27ac[0:train_pos_sample,:]\n",
    "train_neg_pos_H3K27ac = np.concatenate((train_neg_H3K27ac, train_pos_H3K27ac),axis = 0)\n",
    "np.random.shuffle(train_neg_pos_H3K27ac)\n",
    "X_train_H3K27ac = train_neg_pos_H3K27ac[:,0:2080]\n",
    "Y_train_H3K27ac = train_neg_pos_H3K27ac[:,2080]\n",
    "frq = np.bincount(Y_train_H3K27ac)\n",
    "print(frq)\n",
    "print(X_train_H3K27ac.shape)\n",
    "print(Y_train_H3K27ac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1540  823]\n",
      "(2363, 2080)\n",
      "(2363,)\n"
     ]
    }
   ],
   "source": [
    "#val\n",
    "val_neg_sample = train_neg_sample + int(neg_sam_H3K27ac.shape[0] * 0.1)\n",
    "val_pos_sample = train_pos_sample + int(pos_sam_H3K27ac.shape[0] * 0.1)\n",
    "val_neg_H3K27ac = neg_sam_H3K27ac[train_neg_sample:val_neg_sample,:]\n",
    "val_pos_H3K27ac = pos_sam_H3K27ac [train_pos_sample:val_pos_sample,:]\n",
    "val_neg_pos_H3K27ac = np.concatenate((val_neg_H3K27ac, val_pos_H3K27ac),axis = 0)\n",
    "np.random.shuffle(val_neg_pos_H3K27ac)\n",
    "X_val_H3K27ac = val_neg_pos_H3K27ac[:,0:2080]\n",
    "Y_val_H3K27ac = val_neg_pos_H3K27ac[:,2080]\n",
    "frq = np.bincount(Y_val_H3K27ac)\n",
    "print(frq)\n",
    "print(X_val_H3K27ac.shape)\n",
    "print(Y_val_H3K27ac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3081 1647]\n",
      "(4728, 2080)\n",
      "(4728,)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_neg_H3K27ac = neg_sam_H3K27ac[val_neg_sample:,:]\n",
    "test_pos_H3K27ac = pos_sam_H3K27ac [val_pos_sample:,:]\n",
    "test_neg_pos_H3K27ac = np.concatenate((test_neg_H3K27ac, test_pos_H3K27ac),axis = 0)\n",
    "np.random.shuffle(test_neg_pos_H3K27ac)\n",
    "X_test_H3K27ac = test_neg_pos_H3K27ac[:,0:2080]\n",
    "Y_test_H3K27ac = test_neg_pos_H3K27ac[:,2080]\n",
    "frq = np.bincount(Y_test_H3K27ac)\n",
    "print(frq)\n",
    "print(X_test_H3K27ac.shape)\n",
    "print(Y_test_H3K27ac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"H3K27ac_ncl_test\": shape (5270,), type \"|i1\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5filename = \"histonemodKmer_resample_nclx.h5\"\n",
    "h5file = h5.File(h5filename,'a')\n",
    "h5file.create_dataset('/input/H3K27ac_ncl_train',data=X_train_H3K27ac, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/input/H3K27ac_ncl_val', data=X_val_H3K27ac, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/input/H3K27ac_ncl_test', data=X_test_H3K27ac, dtype =np.int8, compression ='gzip')\n",
    "\n",
    "h5file.create_dataset('/output/H3K27ac_ncl_train',data = Y_train_H3K27ac, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/output/H3K27ac_ncl_val', data = Y_val_H3K27ac, dtype =np.int8, compression ='gzip')\n",
    "h5file.create_dataset('/output/H3K27ac_ncl_test', data = Y_test_H3K27ac, dtype =np.int8, compression ='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25743,)\n",
      "[110 111 112 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 144 145 146 148 150 151\n",
      " 152 153 154 155 157 158 159 160 162 163 165 166 167 169]\n"
     ]
    }
   ],
   "source": [
    "h5filename = \"histonemodKmer_resample_nclx.h5\"\n",
    "h5file = h5.File(h5filename,'r')\n",
    "idx = h5file['output/H3K27ac_idx']\n",
    "idx = np.array(idx)\n",
    "print(idx.shape)\n",
    "print(idx[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1065472   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 180)               92340     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                12670     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 1,170,553\n",
      "Trainable params: 1,170,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model = Sequential()\n",
    " #model.add(Conv1D(activation=\"relu\", input_shape=(2080, 1), padding=\"valid\", strides=1, filters=256, kernel_size=11, kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.001)))\n",
    " #model.add(MaxPooling1D(pool_size=4))\n",
    " #model.add(Dropout(0.6))\n",
    " #model.add(Conv1D(activation=\"relu\", padding=\"valid\", strides=1, filters=640, kernel_size=3, kernel_initializer='glorot_uniform', kernel_regularizer=l2(0.001)))\n",
    " #model.add(MaxPooling1D(pool_size=2))\n",
    " #model.add(Dropout(0.5))\n",
    " #model.add(Flatten())\n",
    " #model.summary()\n",
    " model.add(Dense(units=512, input_dim=2080, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    " model.add(Dropout(0.5))\n",
    " #model.add(Dense(units=512, input_dim=512,  activation=\"relu\", kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.001)))\n",
    " #model.add(Dropout(0.5))\n",
    " model.add(Dense(units=180, activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(units=70, activation=\"relu\",kernel_initializer='glorot_uniform'))\n",
    " model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running at most 60 epochs\n",
      "Train on 16543 samples, validate on 2363 samples\n",
      "Epoch 1/50\n",
      "15872/16543 [===========================>..] - ETA: 0s - loss: 0.6571 - acc: 0.6967\n",
      "Epoch 00001: val_loss improved from inf to 0.39433, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 7s 404us/step - loss: 0.6513 - acc: 0.6994 - val_loss: 0.3943 - val_acc: 0.8553\n",
      "Epoch 2/50\n",
      "14848/16543 [=========================>....] - ETA: 0s - loss: 0.4663 - acc: 0.7870\n",
      "Epoch 00002: val_loss improved from 0.39433 to 0.33841, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 31us/step - loss: 0.4643 - acc: 0.7891 - val_loss: 0.3384 - val_acc: 0.8684\n",
      "Epoch 3/50\n",
      "15872/16543 [===========================>..] - ETA: 0s - loss: 0.4177 - acc: 0.8213\n",
      "Epoch 00003: val_loss improved from 0.33841 to 0.32625, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.4188 - acc: 0.8204 - val_loss: 0.3262 - val_acc: 0.8747\n",
      "Epoch 4/50\n",
      "16256/16543 [============================>.] - ETA: 0s - loss: 0.3857 - acc: 0.8413\n",
      "Epoch 00004: val_loss improved from 0.32625 to 0.30698, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.3871 - acc: 0.8405 - val_loss: 0.3070 - val_acc: 0.8828\n",
      "Epoch 5/50\n",
      "16256/16543 [============================>.] - ETA: 0s - loss: 0.3710 - acc: 0.8464\n",
      "Epoch 00005: val_loss improved from 0.30698 to 0.29916, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.3710 - acc: 0.8465 - val_loss: 0.2992 - val_acc: 0.8874\n",
      "Epoch 6/50\n",
      "16000/16543 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8554\n",
      "Epoch 00006: val_loss improved from 0.29916 to 0.29773, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.3558 - acc: 0.8555 - val_loss: 0.2977 - val_acc: 0.8836\n",
      "Epoch 7/50\n",
      "15360/16543 [==========================>...] - ETA: 0s - loss: 0.3401 - acc: 0.8624\n",
      "Epoch 00007: val_loss improved from 0.29773 to 0.29384, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 33us/step - loss: 0.3421 - acc: 0.8619 - val_loss: 0.2938 - val_acc: 0.8900\n",
      "Epoch 8/50\n",
      "16128/16543 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.8681\n",
      "Epoch 00008: val_loss improved from 0.29384 to 0.28709, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 33us/step - loss: 0.3318 - acc: 0.8682 - val_loss: 0.2871 - val_acc: 0.8980\n",
      "Epoch 9/50\n",
      "15488/16543 [===========================>..] - ETA: 0s - loss: 0.3216 - acc: 0.8725\n",
      "Epoch 00009: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.3209 - acc: 0.8720 - val_loss: 0.2872 - val_acc: 0.8976\n",
      "Epoch 10/50\n",
      "15744/16543 [===========================>..] - ETA: 0s - loss: 0.3141 - acc: 0.8784\n",
      "Epoch 00010: val_loss improved from 0.28709 to 0.27927, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 33us/step - loss: 0.3132 - acc: 0.8790 - val_loss: 0.2793 - val_acc: 0.8963\n",
      "Epoch 11/50\n",
      "16512/16543 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.8794\n",
      "Epoch 00011: val_loss improved from 0.27927 to 0.27903, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 32us/step - loss: 0.3064 - acc: 0.8794 - val_loss: 0.2790 - val_acc: 0.8946\n",
      "Epoch 12/50\n",
      "15872/16543 [===========================>..] - ETA: 0s - loss: 0.3011 - acc: 0.8820\n",
      "Epoch 00012: val_loss improved from 0.27903 to 0.27901, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 30us/step - loss: 0.3003 - acc: 0.8820 - val_loss: 0.2790 - val_acc: 0.8959\n",
      "Epoch 13/50\n",
      "15872/16543 [===========================>..] - ETA: 0s - loss: 0.2910 - acc: 0.8855\n",
      "Epoch 00013: val_loss improved from 0.27901 to 0.27631, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 33us/step - loss: 0.2934 - acc: 0.8840 - val_loss: 0.2763 - val_acc: 0.8984\n",
      "Epoch 14/50\n",
      "15616/16543 [===========================>..] - ETA: 0s - loss: 0.2902 - acc: 0.8887\n",
      "Epoch 00014: val_loss improved from 0.27631 to 0.27367, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 30us/step - loss: 0.2911 - acc: 0.8878 - val_loss: 0.2737 - val_acc: 0.8963\n",
      "Epoch 15/50\n",
      "15872/16543 [===========================>..] - ETA: 0s - loss: 0.2817 - acc: 0.8898\n",
      "Epoch 00015: val_loss improved from 0.27367 to 0.27351, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.2827 - acc: 0.8894 - val_loss: 0.2735 - val_acc: 0.8980\n",
      "Epoch 16/50\n",
      "15488/16543 [===========================>..] - ETA: 0s - loss: 0.2786 - acc: 0.8906\n",
      "Epoch 00016: val_loss improved from 0.27351 to 0.27287, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 31us/step - loss: 0.2796 - acc: 0.8906 - val_loss: 0.2729 - val_acc: 0.9006\n",
      "Epoch 17/50\n",
      "15488/16543 [===========================>..] - ETA: 0s - loss: 0.2721 - acc: 0.8946\n",
      "Epoch 00017: val_loss improved from 0.27287 to 0.26882, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 1s 34us/step - loss: 0.2717 - acc: 0.8950 - val_loss: 0.2688 - val_acc: 0.8989\n",
      "Epoch 18/50\n",
      "15360/16543 [==========================>...] - ETA: 0s - loss: 0.2682 - acc: 0.8964\n",
      "Epoch 00018: val_loss improved from 0.26882 to 0.26750, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 30us/step - loss: 0.2665 - acc: 0.8969 - val_loss: 0.2675 - val_acc: 0.8976\n",
      "Epoch 19/50\n",
      "15104/16543 [==========================>...] - ETA: 0s - loss: 0.2588 - acc: 0.8977\n",
      "Epoch 00019: val_loss did not improve\n",
      "16543/16543 [==============================] - 1s 32us/step - loss: 0.2600 - acc: 0.8971 - val_loss: 0.2702 - val_acc: 0.9031\n",
      "Epoch 20/50\n",
      "15744/16543 [===========================>..] - ETA: 0s - loss: 0.2525 - acc: 0.9014\n",
      "Epoch 00020: val_loss improved from 0.26750 to 0.26681, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 30us/step - loss: 0.2525 - acc: 0.9013 - val_loss: 0.2668 - val_acc: 0.8993\n",
      "Epoch 21/50\n",
      "15872/16543 [===========================>..] - ETA: 0s - loss: 0.2493 - acc: 0.9014\n",
      "Epoch 00021: val_loss did not improve\n",
      "16543/16543 [==============================] - 1s 31us/step - loss: 0.2487 - acc: 0.9015 - val_loss: 0.2690 - val_acc: 0.8989\n",
      "Epoch 22/50\n",
      "16128/16543 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.9064\n",
      "Epoch 00022: val_loss improved from 0.26681 to 0.26483, saving model to HistoneMark_H3K27ac.hdf5\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.2407 - acc: 0.9067 - val_loss: 0.2648 - val_acc: 0.8997\n",
      "Epoch 23/50\n",
      "16256/16543 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9082\n",
      "Epoch 00023: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 27us/step - loss: 0.2355 - acc: 0.9082 - val_loss: 0.2652 - val_acc: 0.8989\n",
      "Epoch 24/50\n",
      "14976/16543 [==========================>...] - ETA: 0s - loss: 0.2281 - acc: 0.9115\n",
      "Epoch 00024: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.2298 - acc: 0.9109 - val_loss: 0.2785 - val_acc: 0.9010\n",
      "Epoch 25/50\n",
      "15104/16543 [==========================>...] - ETA: 0s - loss: 0.2210 - acc: 0.9133\n",
      "Epoch 00025: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.2212 - acc: 0.9130 - val_loss: 0.2683 - val_acc: 0.8993\n",
      "Epoch 26/50\n",
      "15104/16543 [==========================>...] - ETA: 0s - loss: 0.2157 - acc: 0.9155\n",
      "Epoch 00026: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.2174 - acc: 0.9154 - val_loss: 0.2659 - val_acc: 0.9006\n",
      "Epoch 27/50\n",
      "15232/16543 [==========================>...] - ETA: 0s - loss: 0.2100 - acc: 0.9184\n",
      "Epoch 00027: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.2101 - acc: 0.9183 - val_loss: 0.2695 - val_acc: 0.9010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "16000/16543 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9209\n",
      "Epoch 00028: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 28us/step - loss: 0.2065 - acc: 0.9210 - val_loss: 0.2708 - val_acc: 0.8997\n",
      "Epoch 29/50\n",
      "16128/16543 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9234\n",
      "Epoch 00029: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 28us/step - loss: 0.1966 - acc: 0.9232 - val_loss: 0.2815 - val_acc: 0.8997\n",
      "Epoch 30/50\n",
      "15360/16543 [==========================>...] - ETA: 0s - loss: 0.1886 - acc: 0.9290\n",
      "Epoch 00030: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 29us/step - loss: 0.1884 - acc: 0.9287 - val_loss: 0.2780 - val_acc: 0.8984\n",
      "Epoch 31/50\n",
      "15744/16543 [===========================>..] - ETA: 0s - loss: 0.1831 - acc: 0.9299\n",
      "Epoch 00031: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 28us/step - loss: 0.1835 - acc: 0.9293 - val_loss: 0.2850 - val_acc: 0.8959\n",
      "Epoch 32/50\n",
      "16000/16543 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9321\n",
      "Epoch 00032: val_loss did not improve\n",
      "16543/16543 [==============================] - 0s 28us/step - loss: 0.1756 - acc: 0.9319 - val_loss: 0.2999 - val_acc: 0.8972\n",
      "Epoch 00032: early stopping\n",
      "4728/4728 [==============================] - 0s 29us/step\n",
      "[0.33261329770189052, 0.89149746202978786]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1065472   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 180)               92340     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                12670     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 1,170,553\n",
      "Trainable params: 1,170,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.937543441037\n",
      "0.906982157012\n",
      "[[2826  255]\n",
      " [ 258 1389]]\n"
     ]
    }
   ],
   "source": [
    " adam = Adam(lr=0.0001)\n",
    " sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    " model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    " print('running at most 60 epochs')\n",
    " checkpointer = ModelCheckpoint(filepath=\"HistoneMark_H3K27ac.hdf5\", verbose=1, save_best_only=True)\n",
    " earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    " model.fit(X_train_H3K27ac, Y_train_H3K27ac, batch_size=128, epochs=50, shuffle=True, validation_data=( X_val_H3K27ac, Y_val_H3K27ac), callbacks=[checkpointer,earlystopper])\n",
    " #model.fit(X_train_s, Y_train_s, batch_size=12, epochs=50, shuffle=True, validation_data=( X_val_s, Y_val_s), callbacks=[checkpointer,earlystopper])\n",
    " y_pred = model.predict(X_test_H3K27ac)\n",
    " #y_pred = model.predict(X_test_s)\n",
    " #tresults = model.evaluate(X_test_s, Y_test_s)\n",
    " np.savetxt('H3K27ac_true.csv', Y_test_H3K27ac, delimiter=\",\")\n",
    " np.savetxt('H3K27ac_pred.csv', y_pred, delimiter=\",\")\n",
    " tresults = model.evaluate(X_test_H3K27ac, Y_test_H3K27ac)\n",
    " print(tresults)\n",
    " model.summary()\t\t\n",
    " #print(roc_auc_score(Y_test_s,y_pred))\n",
    " print(roc_auc_score(Y_test_H3K27ac, y_pred))\n",
    " print(average_precision_score(Y_test_H3K27ac, y_pred))\n",
    " y_pred = (y_pred>0.5)\n",
    " cm = confusion_matrix(Y_test_H3K27ac, y_pred)\n",
    " print(cm)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
